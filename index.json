[{"categories":["Blog"],"contents":"Managed DevOps Pools Have you ever had to deploy, configure, and maintain your own DevOps agents, be it for Azure DevOps or GitHub? If so, then you probably found out it is such a hassle to keep everything up-to-date and up-and-running.\nManaged DevOps Pools have recently been announced as Public Preview. In this article, we go over the most important features and capabilities of the new service and provide examples on how to implement this using Infrastructure as Code with Terraform.\nManaged DevOps Pools, what are they? Managed DevOps Pools are Microsoft-hosted agents that can be configured to use private networking. This allows the agents to use private DNS zones, private endpoints, your own Azure Firewall (or an appliance) and with the added benefit of having Microsoft maintain these resources.\nThe Managed DevOps Pools also allow you to specify which SKU, Disks and OS Images you want to use. So whether you need specific compute power, a lot of disk space, or to use a specific OS Image (even from the Azure Marketplace), Managed DevOps Pools enable you to customize the agent pool to your needs.\nThere are two options to use when it comes to private networking. It can be configured to use an isolated network, which is supplied and managed by Microsoft, or it can use an existing virtual network within the Azure tenant. The added benefit of the latter is that you are able to configure routing, DNS server configuration, and Network Security Groups, managing allowed and denied traffic more specifically for your needs.\nThere is another option that is quite powerful: you can use the Managed DevOps Pools for multiple Azure DevOps organizations and/or multiple projects within these organizations. Some companies use multiple DevOps organizations, i.e. one (1) for production and one (1) for sandbox environments. These can then all use the same Managed DevOps Pool.\nSo what\u0026rsquo;s the managed part then? Although you have to deploy some of the Azure resources yourself, the compute instances behind the scenes are managed by Microsoft. This will actually save you a ton of time and headaches (in my case). The downside of this behind the scenes management is you will not be able to see parts of the solution and therefore troubleshooting might become harder.\nSummary The benefits of Managed DevOps Pools are that while Microsoft will manage them, they are directly usable within your private networking. It has access to lots of images to be used for the agents, be it the Microsoft images, marketplace images, or even custom created images.\nThree key takeways for using Managed DevOps pools By leveraging Managed DevOps Pools, you will have more time to spend on tasks that provide business value, and you will get the same amount of ease and security as you would with self-hosted agents.\nFocus on business value - This service enables me to focus on delivering my business value, instead of maintaining and managing my self-hosted agents. I can automatically use the latest Microsoft hosted agent versions, without having to checkout the repository and build my custom images based on the Microsoft image repository.\nSimplified administrative tasks - Not worrying about the compute instances of the Virtual Machine Scale Set, since those are maintained and managed by Microsoft as a Platform-as-a-Service (PaaS) offering. Also, the Azure DevOps agent pool configuration is done by the Managed DevOps Pool creation, so there is no need to configure Azure DevOps or wait for the Azure DevOps administrator to help out.\nManaged Agents but with private networking - The Managed DevOps Pools can directly use an available virtual network in the Azure tenant, allowing for better access to other services without the need to open up any services to the public internet, as you would have to using Microsoft-hosted agents.\nImplementing DevOps Pools using Infrastructure as Code and Terraform Ok, so let\u0026rsquo;s start with identifying every service that we need and how it all works together.\nOur objective is to set up a Managed DevOps Pool that is able to use private networking, linked to our networking hub, and use the same (Ubuntu) image as the Microsoft-hosted agents.\nWe prefer to use Infrastructure as Code (IaC) to minimize human failure and to create solutions that can be built, changed and managed in a consistent and repeatable way. My preferred IaC language is Terraform, so we will be using Terraform to deploy the resources.\nThis means we will have to perform the following tasks:\nBasic terraform setup - We need to initialize Terraform and the basic repository to be able to deploy the Azure resources Request or update Quotas - Managed DevOps Pool quotas are set to 0 by default, so we will need to request a quota increase in order to use the Managed DevOps Pools Create a resource group - All Azure resources must be deployed into a resource group, so we will create a resource group for the Managed DevOps Pool resources Create a DevCenter and create a project - DevCenter is a collection of projects with similar settings. It can be used to supply catalogs with Infrastructure as Code templates, which are available for all projects in the DevCenter, as well as creating development environments for development teams to use Create a Virtual network, peering to the central hub and create a subnet - To enable private networking, we will need to create a virtual network with a subnet Create the Managed DevOps Pool - The Managed DevOps Pool will create the compute instances that can run the Azure DevOps jobs, and we will supply the correct resource configuration based on the steps before Basic terraform setup When using Terraform, we will need to supply the provider information and configuration. We will be using both the AzureRM and the AzAPI providers. Details on using the AzAPI provider are described in the sections where it applies.\nterraform { required_providers { azurerm = { source = \u0026#34;hashicorp/azurerm\u0026#34; version = \u0026#34;4.0.1\u0026#34; } azapi = { source = \u0026#34;Azure/azapi\u0026#34; version = \u0026#34;1.15.0\u0026#34; } } } provider \u0026#34;azurerm\u0026#34; { subscription_id = \u0026#34;{insert your subscription ID here}\u0026#34; features {} resource_provider_registrations = \u0026#34;Extended\u0026#34; resource_providers_to_register = [\u0026#34;Microsoft.DevCenter\u0026#34;, \u0026#34;Microsoft.DevopsInfrastructure\u0026#34;] } provider \u0026#34;azapi\u0026#34; {} Notice the new annotation for resource providers, which is introduced in the latest AzureRM version.\nAlso notice the providers, which are required to be set on the subscription so the subscription is activated to use the resources within the subscription:\nThe Microsoft.DevCenter provider allows the creation and usage of the DevCenter resource and the projects in the DevCenter. The Microsoft.DevOpsInfrastructure provider enables the subscription to create and deploy the Managed DevOps Pools. Managed DevOps Pools Quotas One important thing to understand before deploying, is that we will need to request a quota increase. These quotas are specifically for Managed DevOps Pools, so your normal Virtual Machine SKU quotas are not valid for the Managed DevOps Pools SKUs.\nYou can request the quotas as you would normally do with other quotas, via the Azure Portal on the subscription page:\nMake sure you select the Provider Managed DevOps Pools to see the quotas:\nIf you do not know how to do this or if the button New Quota Request is greyed out, please reach out to your platform engineers or CSP to help you out.\nVariables and locals I am using a variables.tf and locals.tf file to determine certain values to be used in the deployment, which I will briefly explain in this section.\nThe variables.tf describes all the variables that need to be supplied to run the Terraform deployment. The full file is available in the GitHub repository (available in the links section), but below two variables are shown:\nvariable \u0026#34;scaffold_company_short_name\u0026#34; { description = \u0026#34;Abbreviation of the company name to make all Azure resources unique within the Azure Tenant.\u0026#34; type = string validation { condition = length(var.scaffold_company_short_name) \u0026lt;= 6 error_message = \u0026#34;The company short name must be 6 characters or less.\u0026#34; } } variable \u0026#34;devops_organization_url\u0026#34; { description = \u0026#34;The URL of the Azure DevOps organization to add the Managed DevOps Pool to.\u0026#34; type = string } These variables are used to provide input to re-use the deployment for multiple projects, customers or purposes.\nThe naming convention is provided in the locals.tf file.\nlocals { rgName = \u0026#34;rg-${var.scaffold_company_short_name}-devpool-${var.scaffold_environment}-${var.scaffold_location_short_name}-001\u0026#34; vnetName = \u0026#34;vnet-${var.scaffold_company_short_name}-devpool-${var.scaffold_environment}-${var.scaffold_location_short_name}-001\u0026#34; devCenterName = \u0026#34;devc-${var.scaffold_company_short_name}-${var.scaffold_environment}-${var.scaffold_location_short_name}-001\u0026#34; devCenterProjectName = \u0026#34;devpr-${var.scaffold_company_short_name}-devpool-${var.scaffold_environment}-${var.scaffold_location_short_name}-001\u0026#34; snetName = \u0026#34;snet-${var.scaffold_company_short_name}-devpool-${var.scaffold_environment}-${var.scaffold_location_short_name}-001\u0026#34; poolName = \u0026#34;pool-${var.scaffold_company_short_name}-devpool-${var.scaffold_environment}-${var.scaffold_location_short_name}-001\u0026#34; } Note that the devCenterName value does not contain the -devpool section, this is done to stay within the naming length restriction of 26 characters. We have validations on the variables to ensure this naming convention cannot surpass the length restriction.\nThe locals provide the naming convention that I like to use for this solution. Feel free to change them to your needs or preference accordingly. The naming convention is based on the Cloud Adoption Framework naming convention. Feel free to overwrite these when other naming conventions should apply.\nCreate the resource group Like every Azure resource deployment, we start with creating a Resource Group to place all the Azure resources in.\nresource \u0026#34;azurerm_resource_group\u0026#34; \u0026#34;rg\u0026#34; { name = local.rgName location = var.scaffold_location lifecycle { ignore_changes = [ tags ] } } Create Dev Center resource and a Dev Center Project The basis of the Managed DevOps Pools is the Dev Center resource, along with a DevCenter Project.\nAs described briefly earlier, the DevCenter is a collection of projects with similar settings. It can be used to supply catalogs with Infrastructure as Code templates, which are available for all projects in the DevCenter, as well as creating development environments for development teams to use. A DevCenter Project is contained part that can be made available to specific teams and resources, i.e. Dev Boxes, Deployment Environments or Managed DevOps Pools.\nresource \u0026#34;azurerm_dev_center\u0026#34; \u0026#34;devcenter\u0026#34; { name = local.devCenterName location = azurerm_resource_group.rg.location resource_group_name = azurerm_resource_group.rg.name } The DevCenter name cannot be longer than 26 characters, since we created the variables with validations, we should not reach this number. However, when you update the sample code and update the naming convention or variables, be aware you might reach this naming length restriction.\nresource \u0026#34;azurerm_dev_center_project\u0026#34; \u0026#34;devcenter_project\u0026#34; { name = local.devCenterProjectName dev_center_id = azurerm_dev_center.devcenter.id location = azurerm_resource_group.rg.location resource_group_name = azurerm_resource_group.rg.name } Create the virtual network and subnet Now that we have the Dev Center set up, we can move forward to create the virtual network and subnet to be used by the Managed DevOps Pool to allow for private networking.\nresource \u0026#34;azurerm_virtual_network\u0026#34; \u0026#34;vnet\u0026#34; { name = local.vnetName location = azurerm_resource_group.rg.location resource_group_name = azurerm_resource_group.rg.name address_space = [var.vnet_devpool_ip_range] dns_servers = var.vnet_dns_servers } # Optionally peer the virtual network to the Virtual Hub resource \u0026#34;azurerm_virtual_hub_connection\u0026#34; \u0026#34;agents\u0026#34; { depends_on = [azurerm_virtual_network.vnet] count = var.virtual_hub_id != null ? 1 : 0 name = \u0026#34;conn-${local.vnetName}\u0026#34; internet_security_enabled = true virtual_hub_id = var.virtual_hub_id remote_virtual_network_id = azurerm_virtual_network.vnet.id } Since I am always using a Cloud Platform, I want to link my virtual network to the centralized hub. You can choose to not use this resource, by not providing a value (or providing the value null) to the variable virtual_hub_id, if you do not want to use any connection with a Virtual Hub. If you want to know more about what a hub is, please have a look at the Microsoft Learn pages about hub-and-spokes as part of the Cloud Adoption Framework.\nresource \u0026#34;azapi_resource\u0026#34; \u0026#34;snet\u0026#34; { depends_on = [azurerm_virtual_network.vnet] name = local.snetName type = \u0026#34;Microsoft.Network/virtualNetworks/subnets@2023-11-01\u0026#34; parent_id = azurerm_virtual_network.vnet.id body = jsonencode({ properties = { addressPrefix = var.vnet_devpool_ip_range delegations = [ { name = \u0026#34;Microsoft.DevOpsInfrastructure/pools\u0026#34; properties = { serviceName = \u0026#34;Microsoft.DevOpsInfrastructure/pools\u0026#34; } } ] } }) } Next we use the earlier refered to AzAPI resource in order to create a delegated subnet for the Managed DevOps pool. We need this AzAPI resource because the AzureRM provider does not provide a known terraform configuration for the Microsoft.DevOpsInfrastructure/pools delegation service name. Using the AzAPI resource we can pass our delegation information conveniently.\nCreating the Managed DevOps Pools Now we have the fundamental resources we are going to create the Managed DevOps Pool, again using AzAPI provider.\nresource \u0026#34;azapi_resource\u0026#34; \u0026#34;pool\u0026#34; { name = local.poolName type = \u0026#34;microsoft.devopsinfrastructure/pools@2024-04-04-preview\u0026#34; location = azurerm_resource_group.rg.location parent_id = azurerm_resource_group.rg.id body = jsonencode({ properties = { organizationProfile = { organizations = [ { projects = var.devops_projects url = var.devops_organization_url parallelism = var.agent_maximumConcurrency } ] kind = \u0026#34;AzureDevOps\u0026#34; # Currently only AzureDevOps is supported permissionProfile = { kind = \u0026#34;CreatorOnly\u0026#34; # Can also be set to \u0026#34;Inherit\u0026#34; or \u0026#34;SpecificAccounts\u0026#34; # If you want to use specific accounts, you can add them here using the users and groups properties # users = [ # \u0026#34;Patrick.deKruijf@xebia.com\u0026#34; # ] # groups = [] } } devCenterProjectResourceId = azurerm_dev_center_project.devcenter_project.id maximumConcurrency = var.agent_maximumConcurrency agentProfile = { kind = \u0026#34;Stateless\u0026#34; # I would recommend setting this to \u0026#34;Stateless\u0026#34;, since this ensures a fresh agent is used for each job. # kind = \u0026#34;Stateful\u0026#34; # maxAgentLifetime = \u0026#34;7.00:00:00\u0026#34; # Property is required when set to \u0026#34;Stateful\u0026#34; # If you do not want to turn off scaling, remove the complete resourcePredictionsProfile block # There is also a \u0026#34;Manual\u0026#34; option, which allows you to set the minimum and maximum number of agents based on a schedule. resourcePredictionsProfile = { predictionPreference = \u0026#34;MostCostEffective\u0026#34; # There are 5 options, ranging from \u0026#34;MostCostEffective\u0026#34; to \u0026#34;MostPerformance\u0026#34; kind = \u0026#34;Automatic\u0026#34; # Can also be set to Manual or } } fabricProfile = { sku = { name = \u0026#34;Standard_D2ads_v5\u0026#34; } images = [ { aliases = [\u0026#34;ubuntu-22.04\u0026#34;] buffer = \u0026#34;*\u0026#34; wellKnownImageName = \u0026#34;ubuntu-22.04/latest\u0026#34; }, # You can add more images if needed, also referencing resource IDs for images # { # resourceId = \u0026#34;/Subscriptions/5ab24a52-44e0-4bdf-a879-cc38371a4403/Providers/Microsoft.Compute/Locations/westeurope/Publishers/canonical/ArtifactTypes/VMImage/Offers/0001-com-ubuntu-server-focal/Skus/20_04-lts-gen2/versions/latest\u0026#34;, # buffer = \u0026#34;*\u0026#34; # } ] osProfile = { # Not much to configure here just yet, but Microsoft is working on adding Key Vault support too secretsManagementSettings = { observedCertificates = [], keyExportable = false }, logonType = \u0026#34;Service\u0026#34; # Can also be set to \u0026#34;Interactive\u0026#34; }, # If you want to use an isolated network, remove the complete networkProfile block networkProfile = { subnetId = azapi_resource.snet.id } storageProfile = { osDiskStorageAccountType = \u0026#34;Premium\u0026#34;, # Standard, StandardSSD, Premium dataDisks = [ # Create additional data disks if needed # { # diskSizeGiB = 100 # caching = \u0026#34;ReadWrite\u0026#34; # storageAccountType = \u0026#34;StandardSSD_LRS\u0026#34; # driveLetter = \u0026#34;Z\u0026#34; # } ] }, kind = \u0026#34;Vmss\u0026#34; # Currently only \u0026#34;Vmss\u0026#34; is supported } } }) } For each of the properties a section is created below to explain what each setting expects, what the options are and when you should use a certain option.\nAvailable properties organizationProfile organizationProfile = { organizations = [ { projects = var.devops_projects # This field accepts an Array[] of projects that should be able to use the Managed DevOps Pool url = var.devops_organization_url # This should be the URL of a Azure DevOps organization (i.e. https://dev.azure.com/{organizationName}) parallelism = var.agent_maximumConcurrency # This setting sets the maximum amount of concurrent agents that can be used in parallel } ] kind = \u0026#34;AzureDevOps\u0026#34; # Currently only AzureDevOps is supported, hopefully we can see GitHub here soon too permissionProfile = { kind = \u0026#34;CreatorOnly\u0026#34; # Can also be set to \u0026#34;Inherit\u0026#34; or \u0026#34;SpecificAccounts\u0026#34; users = [ # If you want to use specific accounts, you can add them here using the users and groups properties \u0026#34;Patrick.deKruijf@xebia.com\u0026#34; ] groups = [] # If you want to use specific accounts, you can add them here using the users and groups properties } } devCenterProjectResourceId devCenterProjectResourceId = azurerm_dev_center_project.devcenter_project.id maximumConcurrency maximumConcurrency = var.agent_maximumConcurrency agentProfile agentProfile = { kind = \u0026#34;Stateless\u0026#34; # You can use either \u0026#34;Stateful\u0026#34; or \u0026#34;Stateless\u0026#34;. I would recommend setting this to \u0026#34;Stateless\u0026#34;, since this ensures a fresh agent is used for each job. # maxAgentLifetime = \u0026#34;7.00:00:00\u0026#34; # Property is required when the kind property is set to \u0026#34;Stateful\u0026#34; # If you do not want to turn off scaling, remove the complete resourcePredictionsProfile block # There is also a \u0026#34;Manual\u0026#34; option, which allows you to set the minimum and maximum number of agents based on a schedule. resourcePredictionsProfile = { predictionPreference = \u0026#34;MostCostEffective\u0026#34; # There are 5 options, ranging from \u0026#34;MostCostEffective\u0026#34; to \u0026#34;MostPerformance\u0026#34; kind = \u0026#34;Automatic\u0026#34; # Can also be set to Manual } } fabricProfile = { sku = { name = \u0026#34;Standard_D2ads_v5\u0026#34; # Make sure this SKU is allowed based on the Managed DevOps Pool quotas } images = [ { aliases = [\u0026#34;ubuntu-22.04\u0026#34;] buffer = \u0026#34;*\u0026#34; wellKnownImageName = \u0026#34;ubuntu-22.04/latest\u0026#34; }, # You can add more images if needed, also referencing resource IDs for images # { # resourceId = \u0026#34;/Subscriptions/5ab24a52-44e0-4bdf-a879-cc38371a4403/Providers/Microsoft.Compute/Locations/westeurope/Publishers/canonical/ArtifactTypes/VMImage/Offers/0001-com-ubuntu-server-focal/Skus/20_04-lts-gen2/versions/latest\u0026#34;, # buffer = \u0026#34;*\u0026#34; # } ] osProfile = { # Not much to configure here just yet, but Microsoft is working on adding Key Vault support too secretsManagementSettings = { observedCertificates = [], keyExportable = false }, logonType = \u0026#34;Service\u0026#34; # Can also be set to \u0026#34;Interactive\u0026#34; }, # If you want to use an isolated network, remove the complete networkProfile block networkProfile = { subnetId = azapi_resource.snet.id # This is the resource ID of the virtual network you want to have the Managed DevOps Pool connect to } storageProfile = { osDiskStorageAccountType = \u0026#34;Premium\u0026#34;, # Standard, StandardSSD, Premium dataDisks = [ # Create additional data disks if needed { diskSizeGiB = 100 caching = \u0026#34;ReadWrite\u0026#34; storageAccountType = \u0026#34;StandardSSD_LRS\u0026#34; driveLetter = \u0026#34;Z\u0026#34; } ] }, kind = \u0026#34;Vmss\u0026#34; # Currently only \u0026#34;Vmss\u0026#34; is supported } Required traffic rules (firewall or network security groups) In order to all the resources actually work, you will need to allow traffic to specific domains. So these domains needs to be allowed from a network perspective to make the Managed DevOps Pool functional.\nEndpoints that the Managed DevOps Pool service depends on:\n*.prod.manageddevops.microsoft.com - Managed DevOps Pools endpoint rmprodbuilds.azureedge.net - Worker binaries vstsagentpackage.azureedge.net - Azure DevOps agent CDN location *.queue.core.windows.net - Worker queue for communicating with Managed DevOps Pools service server.pipe.aria.microsoft.com - Common client side telemetry solution (and used by the Agent Pool Validation extension among others) azure.archive.ubuntu.com - Provisioning Linux machines - this is HTTP, not HTTPS www.microsoft.com - Provisioning Linux machines packages.microsoft.com - Provisioning Linux machines ppa.launchpad.net - Provisioning Ubuntu machines dl.fedoraproject.org - Provisioning certain Linux distros Needed by Azure DevOps agent:\ndev.azure.com *.services.visualstudio.com *.vsblob.visualstudio.com *.vssps.visualstudio.com *.visualstudio.com - These entries are the minimum domains required. If you have any issues, see Azure DevOps allowlist for the full list of domains required. For more information regarding the outbound traffic, please see this Microsoft learn page.\nStart the deployment To start the deployment, we will need to provide the deployment with the values for the variables required. See an example file below:\nscaffold_location = \u0026#34;westeurope\u0026#34; scaffold_environment = \u0026#34;production\u0026#34; scaffold_environment_short_name = \u0026#34;prod\u0026#34; scaffold_location_short_name = \u0026#34;weu\u0026#34; scaffold_company_short_name = \u0026#34;{insert-your-company-short-name}\u0026#34; virtual_hub_id = \u0026#34;/subscriptions/{insert-your-hub-subscription-id}/resourceGroups/{insert-your-hub-resource-group-name}/providers/Microsoft.Network/virtualHubs/{insert-your-virtual-hub-name}\u0026#34; vnet_devpool_ip_range = \u0026#34;{insert-your-ip-range}\u0026#34; vnet_dns_servers = [\u0026#34;{insert-your-dns-server-ip}\u0026#34;] agent_maximumConcurrency = 2 # This is the maximum number of agents that can run concurrently, keep in mind the SKU quota you have on your subscription devops_organization_url = \u0026#34;https://dev.azure.com/{insert-your-organization-name}\u0026#34; devops_projects = [\u0026#34;{inset-your-project-name}\u0026#34;, \u0026#34;{insert another project name}\u0026#34;] Since we\u0026rsquo;re using Terraform, we can simply run the following commands:\nterraform init # This will initialize the backend settings and install the required providers terraform validate # This will check if all terraform plan --var-file=test.tfvars # This will execute a \u0026#39;dry-run\u0026#39; to see what would be created, modified or removed, using the tfvars-file referenced terraform apply --var-file=test.tfvars # This will firstly do another dry-run, asking a \u0026#39;yes\u0026#39; to continue with the actual deployment, using the tfvars-file referenced Note that this will create a local Terraform state file, which is fine for my demo purposes. When you are using this is a production environment, please update the state backend accordingly.\nFor the explaination of the deployment and required steps, we use the commands directly into a terminal. We prefer and recommend to use Azure Pipelines or GitHub Actions to deploy Infrastructure as Code.\nCost of using DevOps Pools Managed DevOps Pools pricing is determined by the cost of the Azure services your pool uses, like compute, storage, and data egress, combined with the standard Azure DevOps Services pricing for self-hosted agents.\nAzure Services - The Managed DevOps Pool uses Azure resources to supply the functionality. These resources will be billed to your Azure subscription. During public preview there are no extra costs for the Managed DevOps Pools resource itself Azure DevOps Services - The cost for the DevOps Services are tied to the costs of self-hosted agents, this means that you will have to pay for parallel jobs. The first parallel job is free, then it is set to $15 per additional parallel job. Please note that parallel jobs are shared between all pipelines and pool in your organization.\nConclusion In my opinion using Managed DevOps Pools is definately worth it. You get the ease of mind, because it is a PaaS offering. It directly integrates into your private network within your Azure tenant, allowing for better and safer connections. And with the code repository, you will get a quick starter template to be able to use it. A Managed DevOps Pool is only available for the teams that have access to it and you can created multiple pools with different settings, i.e. a CPU-intensive pool and a Memory-intensive pool for different teams.\nMicrosoft is also considering adding support for container-based agents to improve on-demand spin up times. I am excited to see the improvements in the future!\nAdditional information Origin story In case you want to read more about the origin story, please read the story by Suraj Gupta and Elize Tarasila\nLinks Code Repository Microsoft Learn Origin Story Public preview announcement ","date":"08 Oct, 2024","image":null,"permalink":"/post/managed-devops-pools/","tags":["Azure Policy","Xpirit Magazine","Governance"],"title":"Azure Managed DevOps Pools"},{"categories":["Blog"],"contents":"This article is written for the Xpirit Magazine #15\nImagine your company having a multitude of azure resources, and you want to ensure that all of them are compliant with your company\u0026rsquo;s standards. You could go through each resource and check if they are compliant, but that would be a lot of work. Luckily, Azure Policy can help you with that. Azure Policy is a management tool that helps you enforce and control the settings and configurations of resources within your Azure cloud environment. It enables you to define and enforce rules and policies to ensure that your resources adhere to specific compliance and governance requirements. These policies can cover various aspects, such as security, resource tagging, and naming conventions, helping you maintain a consistent and secure cloud infrastructure. Azure Policy provides a centralized way to monitor and enforce these policies, ensuring that your Azure resources are aligned with your organization\u0026rsquo;s standards and best practices.\nAzure Policy works with definitions to set the conditions and rules to be executed. Definitions dictate the logic, followed by assignments that apply the logic to a scope. A scope can be a management group, subscription, resource group, or resource. When an assignment is made, you can review the compliance of your resources in the compliance dashboard.\nWhen you are ready to look at Azure Policy, you will probably be overwhelmed. Luckily, Microsoft Azure has supplied you with a set of built-in policies that you can use to get started. Additionally, when the built-in policies are not sufficient for your needs, you have the option to create custom policies. Below a short summary of the differences:\nBuilt-in policy definitions are provided by Microsoft and can be used to audit your environment against. Custom policy definitions are created by you and can be used to audit your environment against. Important note for built-in policies, they are deployed to the Root Tenant Group and their names are GUIDs. Their display name will explain better what each policy definition does.\nWhy would I use it? Azure Policy is quite powerful and enables your organization to enforce standards and assess compliance. It also helps to bring your resources to compliance through bulk remediation for existing resources and automatic remediation for new resources. But why would you use it? Let’s take a look at some of the benefits of using Azure Policy:\nEnforce standards: Azure Policy helps to enforce standards and assess compliance. You can also use policies to prevent or (automatically) remediate non-compliant resources. Centralized management: Azure Policy provides a centralized management experience for all your policies. You can create, assign, and manage policies from a single location. Aggregated view: Azure Policy provides an aggregated view of the state of your environment through the compliance dashboard, which shows the overall state of the environment and allows you to view the state of individual resources or policies. Built-in compliance standards: Azure Policy provides built-in compliance standards that can be used to audit your environment against. These standards include CIS, PCI, HIPAA, ISO, NIST, SOC, and more. Bring resources to compliance: Azure Policy helps to bring your resources to compliance through bulk remediation for existing resources and automatic remediation for new resources. Custom compliance standards: Azure Policy provides the ability to create custom compliance standards that can be used to audit your environment against. Audit and remediate: Azure Policy provides the ability to audit and remediate your environment. You can audit your environment by using the audit effect. You can remediate your environment by using the deployIfNotExists effect. Steer user behavior: Azure Policy can be used to steer user behavior by restricting the use of specific resource types. For example, you can restrict the use of public IP\u0026rsquo;s. Now we know why we would use Azure Policy, let\u0026rsquo;s take a look at some of the real life scenario\u0026rsquo;s that can be solved with Azure Policy:\nRestricting the location of resources i.e., all resources should be deployed in West Europe or North Europe Enforcing tagging on resources i.e., all resources should have a cost center tag Steer user behavior by restricting the use of specific resource types or SKUs i.e., no use of public IP\u0026rsquo;s, deny creation of GPU VM\u0026rsquo;s Enforcing the configuration of specific resource configurations i.e., soft delete on key vaults, or encryption on storage accounts Configure DNS Private Zone settings automatically on private endpoints i.e., configure the DNS Private Zone settings on private endpoints to use the private DNS zone Enforce resource naming for Resource Groups i.e., all resource groups should start with rg- How do I use Azure Policy? First, you start with a policy definition that dictates the logic to execute. This can be either a built-in or custom policy. Built-in policies are deployed to the Root Tenant Group and therefor available everywhere in your Management Group and Subscription hierachie. Custom policies are deployed to a specific scope and therefor only available in that scope or a child scope. The deployment of a policy definition is nothing more than making the policy definition available to be used.\nIn order to apply the logic of a policy definition to a certain scope, which can be the scope the policy definition was deployed to or any of the child scope in the hierachie. You will need to create a policy assignment. A policy assignment is the actual assignment of the policy definition to a scope. The policy assignment will evaluate the resources in the scope against the policy definition. The policy assignment will also show the compliance of the resources in the scope.\nBut what if I want to combine multiple policy definitions and assign it as part of a single policy? This is where policy initiatives come in. Policy initiatives are a collection of one or more policy definitions. Like policy definitions, these are deployed to a specific scope and can be assigned to a scope. The assignment of a policy initiative is the same as the assignment of a policy definition.\nPolicy Definitions A policy definition is a JSON document that defines the logic of the policy. Let\u0026rsquo;s create a policy definition together.\nName: The name of the policy definition. Description: A description of the policy definition. PolicyRule: The policy rule that defines the logic of the policy definition. Metadata: Metadata about the policy definition. Parameters: Parameters that can be used in the policy rule. Name The name of the policy definition. The name is used to identify the policy definition. The name must be unique within the scope of the policy definition.\nDescription A description of the policy definition. The description is used to describe the policy definition. The description is optional.\nPolicyRule Policy definitions are using policy rules to dictate the logic to perform or validate. These rules are built using an if-then construct. The IF part contains the resource(s) to search for, the THEN part contains action to take.\nThe IF-part of the policy rules The IF parts there are multiple options to identify the scope for the policy. These are using logical operators to check the conditions. Within the logical operators, conditions are used to determine if the policy should execute the THEN part. You can use the following operators:\nnot - the conditions should not be true (inverting the result). allOf - each condition in the block, should be true. anyOf - any condition in the block, should be true. With these logical operators you are flexible in terms of identifying which resources should be used in the specific policy. You can even use nested operators. The logical operators use conditions to identify when to perform the THEN part of the policy. Conditions are always described with a field value and an option that returns a true or false result. Possible options are:\nequals – true if the field value matches the equals value. notEquals – true the field value does not match the notEquals value. exists – true if the field value exists. in - true if the field value is in the list of values. The field values can contain a multitude of different options. Let’s go over some of the commonly used options:\nType indicates the actual resource type (i.e., \u0026ldquo;Microsoft.KeyVault/vaults\u0026rdquo;) Location indicates the resource location (i.e., \u0026ldquo;WestEurope\u0026rdquo;) Id indicates the actual resource ID of an Azure resource (see properties on a resource to view/copy the resource ID) Aliases can be used to access property of a resource type. And many more. The THEN-part of policy rules For the THEN part, Azure Policy uses an effect to identify the action to be taken when the conditions of the definition or initiative are non-compliant. Eight types of effects are available:\nDeny will ensure the non-compliant resource cannot be created or deployed. Audit will audit the resources’ compliance and show the status in the compliance dashboard. DeployIfNotExists will deploy the configuration specified in the definition to the resource if the configuration does not exist. AuditIfNotExists will audit the configuration specified in the definition and only report if the resource configuration does not exist. Modify is used to add, update, or remove properties or tags on a subscription or resource during creation or update. Append is used to add more fields to the requested resource during creation or update. Manual enables you to self-attest the compliance of resources or scopes. Disabled means that the logic in the definition will effectively do nothing and is turned off. Metadata Metadata about the policy definition. The metadata is used to provide additional information about the policy definition. The metadata is optional. Common metadata properties are:\nCategory: The category of the policy definition. Version: The version of the policy definition. Deprecated: Indicates if the policy definition is deprecated. Preview: Indicates if the policy definition is in preview. Parameters Parameters are optional. They can be used to make the policy definition more flexible. Parameters are defined in the parameters section of the policy definition. Parameters are referenced in the policy rule by using the following syntax: [parameters('parameterName')]. Parameters will be prompted for when assigning the policy definition.\nResult Let’s take a look at an example of a policy definition. The following policy definition is used to audit the use of the Microsoft.Storage/storageAccounts/networkAcls/defaultAction property. The policy definition is named audit-storage-account-network-acl-default-action and has the following properties:\nDescription: Audit the use of the Microsoft.Storage/storageAccounts/networkAcls/defaultAction property. PolicyRule: If the type of the resource is Microsoft.Storage/storageAccounts and the Microsoft.Storage/storageAccounts/networkAcls/defaultAction property is not equal to Deny, then audit the resource. Metadata: The category is Storage and the version is 1.0.0. { \u0026#34;properties\u0026#34;: { \u0026#34;displayName\u0026#34;: \u0026#34;Audit storage account network ACL default action\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Audit the use of the Microsoft.Storage/storageAccounts/networkAcls/defaultAction property.\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;Indexed\u0026#34;, \u0026#34;policyRule\u0026#34;: { \u0026#34;if\u0026#34;: { \u0026#34;allOf\u0026#34;: [ { \u0026#34;field\u0026#34;: \u0026#34;type\u0026#34;, \u0026#34;equals\u0026#34;: \u0026#34;Microsoft.Storage/storageAccounts\u0026#34; }, { \u0026#34;field\u0026#34;: \u0026#34;Microsoft.Storage/storageAccounts/networkAcls/defaultAction\u0026#34;, \u0026#34;notEquals\u0026#34;: \u0026#34;Deny\u0026#34; } ] }, \u0026#34;then\u0026#34;: { \u0026#34;effect\u0026#34;: \u0026#34;audit\u0026#34; } }, \u0026#34;metadata\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Storage\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34; } } } Examples I only want to allow resources to be deployed in the West Europe region. This can be achieved by using the DENY effect, it will verify the condition and it will DENY the deployment if the condition returns as true.\nIn this case IF the location is not equal to WestEurope returns true THEN we DENY the deployment.\n\u0026#34;policyRule\u0026#34;: { \u0026#34;if\u0026#34;: { \u0026#34;not\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;location\u0026#34;, \u0026#34;equals\u0026#34;: \u0026#34;WestEurope\u0026#34; } }, \u0026#34;then\u0026#34;: { \u0026#34;effect\u0026#34;: \u0026#34;Deny\u0026#34; } } I want to always add soft delete on key vaults on creation. For this scenario we can use APPEND as the effect, we will verify if the condition if true and then we will append a specific configuration/property.\nIn this case, we verify IF the type of the resource is a Key Vault and if the soft delete option is not true.When the conditions have been verified, we will THEN APPEND the soft delete option.\n\u0026#34;policyRule\u0026#34;: { \u0026#34;if\u0026#34;: { \u0026#34;anyOf\u0026#34;: [ { \u0026#34;allOf\u0026#34;: [ { \u0026#34;field\u0026#34;: \u0026#34;type\u0026#34;, \u0026#34;equals\u0026#34;: \u0026#34;Microsoft.KeyVault/vaults\u0026#34; }, { \u0026#34;field\u0026#34;: \u0026#34;Microsoft.KeyVault/vaults/enableSoftDelete\u0026#34;, \u0026#34;notEquals\u0026#34;: true } ] } ] }, \u0026#34;then\u0026#34;: { \u0026#34;effect\u0026#34;: \u0026#34;append\u0026#34;, \u0026#34;details\u0026#34;: [ { \u0026#34;field\u0026#34;: \u0026#34;Microsoft.KeyVault/vaults/enableSoftDelete\u0026#34;, \u0026#34;value\u0026#34;: true } ] } } How do I deploy policy definitions? As always with cloud resources, the preferably way to deploy them is using Infrastructure as Code (IaC). Azure Policy definitions can be deployed using ARM templates, Azure CLI, Bicep, Terraform, or PowerShell. The following example shows how to deploy the policy definition using a PowerShell script:\nNew-AzPolicyDefinition -Name \u0026#39;audit-storage-account-network-acl-default-action\u0026#39; -DisplayName \u0026#39;Audit storage account network ACL default action\u0026#39; -Description \u0026#39;Audit the use of the Microsoft.Storage/storageAccounts/networkAcls/defaultAction property.\u0026#39; -Policy \u0026#39;audit-storage-account-network-acl-default-action.json\u0026#39; -Mode All Important to note is that the PowerShell cmdlet uses the -Policy argument to define the Policy Rule. Each of the important parts of the policy definition is defined in the cmdlet.\nFile: audit-storage-account-network-acl-default-action.json:\n{ \u0026#34;if\u0026#34;: { \u0026#34;anyOf\u0026#34;: [ { \u0026#34;allOf\u0026#34;: [ { \u0026#34;field\u0026#34;: \u0026#34;type\u0026#34;, \u0026#34;equals\u0026#34;: \u0026#34;Microsoft.KeyVault/vaults\u0026#34; }, { \u0026#34;field\u0026#34;: \u0026#34;Microsoft.KeyVault/vaults/enableSoftDelete\u0026#34;, \u0026#34;notEquals\u0026#34;: true } ] } ] }, \u0026#34;then\u0026#34;: { \u0026#34;effect\u0026#34;: \u0026#34;append\u0026#34;, \u0026#34;details\u0026#34;: [ { \u0026#34;field\u0026#34;: \u0026#34;Microsoft.KeyVault/vaults/enableSoftDelete\u0026#34;, \u0026#34;value\u0026#34;: true } ] } } Policy Initiatives A policy initiative is a collection of one or more policy definitions. Policy initiatives are used to group policy definitions together. This can be useful when you want to assign multiple policy definitions to a scope. Instead of assigning each policy definition individually, you can assign the policy initiative. The policy initiative will then assign all the policy definitions that are part of the policy initiative. Let’s create a policy initiative together.\n{ \u0026#34;properties\u0026#34;: { \u0026#34;displayName\u0026#34;: \u0026#34;Audit storage account network ACL\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Audit the use of the Microsoft.Storage/storageAccounts/networkAcls/defaultAction property and the Microsoft.Storage/storageAccounts/networkAcls/bypass property.\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;category\u0026#34;: \u0026#34;Storage\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34; }, \u0026#34;policyDefinitions\u0026#34;: [ { \u0026#34;policyDefinitionId\u0026#34;: \u0026#34;/providers/Microsoft.Authorization/policyDefinitions/audit-storage-account-network-acl-default-action\u0026#34;, \u0026#34;parameters\u0026#34;: {} }, { \u0026#34;policyDefinitionId\u0026#34;: \u0026#34;/providers/Microsoft.Authorization/policyDefinitions/audit-storage-account-network-acl-bypass\u0026#34;, \u0026#34;parameters\u0026#34;: {} } ] } } How do I deploy policy initiatives? As always with cloud resources, the preferably way to deploy them is using Infrastructure as Code (IaC). Azure Policy initiatives can be deployed using ARM templates, Bicep, Terraform, or PowerShell. The following example shows how to deploy the policy initiative using a Terraform:\n# Create a new policy initiative using the policy definitions supplied in the audit-storage-account-network-acl.json file New-AzPolicySetDefinition -Name \u0026#39;audit-storage-account-network-acl\u0026#39; -PolicyDefinition \u0026#39;audit-storage-account-network-acl.json\u0026#39; File: audit-storage-account-network-acl.json:\n[ { \u0026#34;policyDefinitionId\u0026#34;: \u0026#34;/providers/Microsoft.Authorization/policyDefinitions/audit-storage-account-network-acl-default-action\u0026#34;, \u0026#34;parameters\u0026#34;: {} }, { \u0026#34;policyDefinitionId\u0026#34;: \u0026#34;/providers/Microsoft.Authorization/policyDefinitions/audit-storage-account-network-acl-bypass\u0026#34;, \u0026#34;parameters\u0026#34;: {} } ] Policy Assignments A policy assignment is the actual assignment of the policy definition or policy initiative to a scope. The policy assignment will evaluate the resources in the scope against the policy definition or policy initiative. The policy assignment will also show the compliance of the resources in the scope. Let’s create a policy assignment together, using PowerShell.\n# Get the subscription data $Subscription = Get-AzSubscription -SubscriptionName \u0026#39;Subscription01\u0026#39; # Get the policy definition data $Policy = Get-AzPolicyDefinition -Name \u0026#39;audit-storage-account-network-acl-default-action\u0026#39; # Create the policy assignment using the retrieved subscription and policy definition data New-AzPolicyAssignment -Name \u0026#39;audit-storage-account-network-assignment\u0026#39; -PolicyDefinition $Policy -Scope \u0026#34;/subscriptions/$($Subscription.Id)\u0026#34; How can I see my resource compliance? After you\u0026rsquo;ve have created and assigned your policies, you can view the compliance of your resources. The compliance dashboard provides an aggregated view of the state of your environment. It shows the overall state of the environment and allows you to view the state of individual resources or policies. The compliance dashboard can be found in the Azure Portal under All services \u0026gt; Policy \u0026gt; Compliance.\nRegulatory compliance In order to view regulatory compliance, Microsoft Azure also uses Azure Policy to report on the compliance state of the regulatory compliance standards you have assigned. Whenever you select a regulatory compliance standard, Azure Policy will automatically create a policy assignment to audit the compliance state of the regulatory compliance standard. Azure Defender for Cloud also uses the input from Azure Policy to show recommendations in the Azure Portal.\nTo view the compliance state of the regulatory compliance standards you have assigned, you can use the regulatory compliance dashboard. The regulatory compliance dashboard can be found in the Azure Portal under All services \u0026gt; Microsoft Defender for Cloud \u0026gt; Regulatory compliance.\nHow does remediation work? Remediation is the process of bringing a non-compliant resource into compliance. When remediation is done manually, you can trigger the remediation from the compliance dashboard. When remediation should be done automatically, which is only possible when using the DeployIfNotExists or Modify effect, you can configure the policy to automatically remediate non-compliant resources. In order for the policy to remediate automatically, it will use a managed identity. This managed identity should be supplied in the policy assignment. In order to use the remediation, you need to specify, in the policy definition, which role the managed identity should have on the resource. The policy assignment will start the deployment to perform the remediation task. When using the DeplyoIfNotExists effect, the deployment will be visible in the deployment dashboard so you can track and troubleshoot the deployment.\nAutomatic remediation Let\u0026rsquo;s use a built-in policy definition to show how automatic remediation works. The built-in policy definition is named Add or replace a tag on resource groups and has the following PolicyRule logic:\n{ \u0026#34;if\u0026#34;: { \u0026#34;allOf\u0026#34;: [ { \u0026#34;field\u0026#34;: \u0026#34;type\u0026#34;, \u0026#34;equals\u0026#34;: \u0026#34;Microsoft.Resources/subscriptions/resourceGroups\u0026#34; }, { \u0026#34;field\u0026#34;: \u0026#34;[concat(\u0026#39;tags[\u0026#39;, parameters(\u0026#39;tagName\u0026#39;), \u0026#39;]\u0026#39;)]\u0026#34;, \u0026#34;notEquals\u0026#34;: \u0026#34;[parameters(\u0026#39;tagValue\u0026#39;)]\u0026#34; } ] }, \u0026#34;then\u0026#34;: { \u0026#34;effect\u0026#34;: \u0026#34;modify\u0026#34;, \u0026#34;details\u0026#34;: { \u0026#34;roleDefinitionIds\u0026#34;: [ \u0026#34;/providers/microsoft.authorization/roleDefinitions/b24988ac-6180-42a0-ab88-20f7382dd24c\u0026#34; ], \u0026#34;operations\u0026#34;: [ { \u0026#34;operation\u0026#34;: \u0026#34;addOrReplace\u0026#34;, \u0026#34;field\u0026#34;: \u0026#34;[concat(\u0026#39;tags[\u0026#39;, parameters(\u0026#39;tagName\u0026#39;), \u0026#39;]\u0026#39;)]\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;[parameters(\u0026#39;tagValue\u0026#39;)]\u0026#34; } ] } } } The policy definition will check if the resource type is a resource group and if the tag is not equal to the specified value. If the conditions are true, the policy will modify the resource group and add or replace the specified tag.\nAs described ealier, we should create a policy assignment to make this logic active on a certain scope, let\u0026rsquo;s create a policy assignment together, using PowerShell.\n# Get the subscription data $Subscription = Get-AzSubscription -SubscriptionName \u0026#39;Subscription01\u0026#39; # Get the policy definition data, using a Where-Object, since built-in policies are named with a GUID $Policy = Get-AzPolicyDefinition | Where-Object {$_.Properties.DisplayName -eq \u0026#39;Add or replace a tag on resource groups\u0026#39;} # Define the parameters for the policy assignment to pass to the -PolicyParameterObject parameter $parameters = @{\u0026#39;tagName\u0026#39;=\u0026#39;Environment\u0026#39;;\u0026#39;tagValue\u0026#39;=\u0026#39;Production\u0026#39;} # Create the policy assignment using the retrieved subscription and policy definition data New-AzPolicyAssignment -Name \u0026#39;add-tag-resource-group\u0026#39; -PolicyDefinition $Policy -Scope \u0026#34;/subscriptions/$($Subscription.Id)\u0026#34; -IdentityType \u0026#39;SystemAssigned\u0026#39; -Location \u0026#39;WestEurope\u0026#39; -PolicyParameterObject $parameters The policy assignment will automatically remediate the resource group and add or replace the specified tag. The deployment will be visible in the deployment dashboard so you can track and troubleshoot the deployment.\nSo what happens when you create a resource group without the specified tag? Let\u0026rsquo;s try it out!\n# Set the subscription context Set-AzContext -Subscription \u0026#39;Subscription01\u0026#39; # Create a new resource group without the specified tag New-AzResourceGroup -Name \u0026#39;rg-remediation-test\u0026#39; -Location \u0026#39;WestEurope\u0026#39; As you can see, the resource group is created without the specified tag and the output already shows that the policy assignment has remediated the resource group. When we check the resource group, we can see that the tag is added.\nManual remediation Let\u0026rsquo;s use the same example as with the automatic remediation, but we have now changed the policy to seek the TagName:Demo with a TagValue:ManualRemediation.\n# Get the subscription data $Subscription = Get-AzSubscription -SubscriptionName \u0026#39;Subscription01\u0026#39; # Get the policy definition data, using a Where-Object, since built-in policies are named with a GUID $Policy = Get-AzPolicyDefinition | Where-Object {$_.Properties.DisplayName -eq \u0026#39;Add or replace a tag on resource groups\u0026#39;} # Define the parameters for the policy assignment to pass to the -PolicyParameterObject parameter $parameters = @{\u0026#39;tagName\u0026#39;=\u0026#39;Demo\u0026#39;;\u0026#39;tagValue\u0026#39;=\u0026#39;ManualRemediation\u0026#39;} # Create the policy assignment using the retrieved subscription and policy definition data New-AzPolicyAssignment -Name \u0026#39;add-tag-resource-group\u0026#39; -PolicyDefinition $Policy -Scope \u0026#34;/subscriptions/$($Subscription.Id)\u0026#34; -IdentityType \u0026#39;SystemAssigned\u0026#39; -Location \u0026#39;WestEurope\u0026#39; -PolicyParameterObject $parameters Since the policy is not compliant, we can manually remediate the resource group by clicking on the Create Remediation Task button in the assignment page on the subscription.\nAfter the remediation task has been created, we can see the task in the remediation tasks overview. And you should even see a completed remediation task.\nExemptions Sometimes you want to exclude certain resources from being evaluated by a policy. This can be done by using exemption. Exemptions can be made on policy assignments and on individual resources. Exemptions can be made for a specific amount of time or indefinitely. Exemptions can be made for the following reasons:\nMitigation: The resource is already mitigated. False positive: The resource is evaluated as non-compliant, but it is compliant. Business justification: The resource is evaluated as non-compliant, but it is compliant for business reasons. Waiver: The resource is evaluated as non-compliant, but it is compliant for legal reasons. How do I create an exemption? Exemptions can be created using the Azure Portal, PowerShell, Azure CLI, or REST API. Let\u0026rsquo;s create an exemption using PowerShell.\n# Get the subscription data $Subscription = Get-AzSubscription -SubscriptionName \u0026#39;Subscription01\u0026#39; # Get the policy assignment data $PolicyAssignment = Get-AzPolicyAssignment -Name \u0026#39;add-tag-resource-group\u0026#39; -Scope \u0026#34;/subscriptions/$($Subscription.Id)\u0026#34; # Create the exemption New-AzPolicyExemption -Name \u0026#39;exemption-add-tag-resource-group\u0026#39; -PolicyAssignment $PolicyAssignment -ExemptionCategory \u0026#39;Waiver\u0026#39; -ExpiresOn (Get-Date).AddDays(7) Now what? Now that you know what Azure Policy is and how to use it, you can start using it in your own environment. Start with the built-in policies and see if they fit your needs. If they don\u0026rsquo;t, you can always create custom policies.\nIf you want to explore and view anything policy related in the Azure Portal, simply go to All services \u0026gt; Policy. Here you can view the compliance dashboard, policy definitions, policy initiatives, policy assignments, and exemptions.\nIf you want to know which Azure Policies are built-in available, AzAdvertizer is a great resource to view all the built-in policies.\n","date":"25 Oct, 2023","image":null,"permalink":"/post/azure-policy/","tags":["Azure Policy","Xpirit Magazine","Governance"],"title":"Azure Policy - Magazine article"},{"categories":["Blog"],"contents":"In 2022 I published an article in our Xpirit Magazine #13 about Azure Virtual Desktop. In this post I will give you a summary of the article.\nWhat is Azure Virtual Desktop? Azure Virtual Desktop is Microsoft\u0026rsquo;s desktop and app virtualization Virtual Desktop Infrastructure (VDI) service that runs on Microsoft Azure. Azure Virtual Desktop allows for multi-session virtual machines with scalability on Azure and enables organizations to centrally provide users with a personalized Windows desktop experience, while also providing the flexibility to support a variety of devices and operating systems. It is a Platform as a Service (PaaS) solution that provides a complete desktop and app virtualization solution for Windows.\nBe sure to read the glossary item about Azure Virtual Desktop for more information.\nWhat can you used Azure Virtual Desktop for? Traditional Azure Virtual Desktop is the cloud version of Remote Desktop Services (RDS), a Virtual Desktop Infrastructure service. A Virtual Desktop Infrastructure service is commonly used for a fully working business desktop with all the required applications for your business. This means that it can create a fully working workplace for your employees or contractors in the cloud without having to invest in physical hardware that is capable of running everything locally.\nNiche Since Azure Virtual Desktop can also host and present an application to end-users and give them a seamless user experience (you experience the application as if it runs locally on your machine), this will mean that you, as a business, can distribute your application online with the scalability and flexibility of the Azure cloud and the control of your application. Although you could use this as an extension of your full desktop experience, this is also the basis for a niche use case.\nWhat we mean with a niche use case for Azure Virtual Desktop is that your organization can provide centrally managed applications to your end-users, even though your application might not be fully cloud-native (yet). This use case could help organizations move to the Microsoft Azure cloud.\nOur customers and Azure Virtual Desktop Some customers have an application that is not cloud-native (yet), some customers want control over the installation and configuration of their application, and some want to not burden their customers with application configuration or setup. We have encountered these different reasons at our customers, and we have helped tackle them with Azure Virtual Desktop. The applications are still being improved to be cloud-native, but while the development and improvements are performed, we can move to the cloud quicker while adding scalability and flexibility in the Microsoft Azure cloud\nKongsberg Digital Kongsberg Digital have innovative maritime simulation solutions which are available both online and offline. Kongsberg Digital Maritime simulations are part of the K-SIM product line. One part of the K-SIM product line is the K-SIM Instructor, where instructors and trainers can create simulation exercises for students to execute and perform. The K-SIM Instructor application is a Windows desktop application for instructors to use locally. The installation and use of the K-SIM Instructor application requires other K-SIM tools, models, and area charts. These requirements add complexity for the instructors.\nAzure Virtual Desktop helps Kongsberg Digital Maritime to take ownership of the installation and configuration part of the K-SIM Instructor application and the end users don\u0026rsquo;t need to install anything on their machines. The K-SIM Instructor application also has strict compatibility requirements with the simulator engine for the students to execute and perform the simulations in the K-SIM Connect cloud environment. Since Kongsberg Digital Maritime is in control over the complete installation and configuration of both the K-SIM Instructor application and the simulator engine versions, the compatibility requirements are centrally managed and guaranteed compatible.\nAzure Virtual Desktop as a cloud accelerator Azure Virtual Desktop is a quick and straightforward way to start your cloud journey by providing a solution for your traditional desktop applications. It is low maintenance, deployable using Infrastructure as Code, and has no or low requirements of client systems to start working. While using the Azure Virtual Desktop service, you will improve your organization\u0026rsquo;s knowledge and experience what the Microsoft Azure cloud can offer your organization.\nThe time-to-market is very fast while adding many other cloud benefits at the same time.\nWhat services do you need for Azure Virtual Desktop Azure Virtual Desktop is a service that handles the management layer for providing a Virtual Desktop Infrastructure service. The Azure Virtual Desktop service consists of a few main areas:\nWorkspaces - Workspaces are a logical group of one or more application groups. Application Groups - Within Application Groups, the applications and desktopsare configured, including user and group assignment. The Application Groups are logical groups of installed software on the sessions hosts within the host pool(s) Host Pools - The Host Pools are one or more pools of session hosts providing the computing power for the application groups. Scaling plans - Scaling plans are used for ramping hosts up or down based on session usage and peak- and off-peak hours. An Azure Virtual Desktop host pool requires either a Virtual Machine service or Virtual Machine Scale Set service to provide the computing power on which the applications are installed and running. These services require a Windows Image, which you can build yourself or use an available images from the Microsoft Azure cloud.\nThe identity provider for Azure Virtual Desktop can be either Azure Active Directory or a traditional Active Directory Domain Services domain.\nTo make sure the user experiences their profile the same on all hosts, we are using FSLogix profile containers, which are stored on an Azure file share. FSLogix enhances and enables user profiles in Windows remote computing environments and is able to supply profile containers, office containers, and application masking.\nCan I try it myself? Yes, you can! We have set up a GitHub Repository for you to deploy Azure Virtual Desktop with Bicep. Our Azure Virtual Desktop GitHub repository contains all the bicep files you need to run an Azure Virtual Desktop in the cloud with a default app.\n","date":"09 Jan, 2023","image":null,"permalink":"/post/azure-virtual-desktop-magazine13/","tags":["AVD / WVD","Xpirit Magazine","Azure Virtual Desktop"],"title":"Azure Virtual Desktop - Magazine article"},{"categories":["Blog"],"contents":"My articles regarding Azure Virtual Desktop and Azure Landing Zones are in the Xpirit Magazine #13. In this blog, I\u0026rsquo;m explaining how my daily job tasks got an epic place in the Xpirit Magazine!\nImagine you are doing your everyday work for your customers and suddenly you get a message from our internal magazine editors asking if you want to write an article for the magazine. That is exactly what happened to me last year, Arjan van Bekkum reached out to encourage me to write an article for our 13th edition!\nI was working on a project for Kongsberg Digital where I was implementing an Azure Virtual Desktop solution in a slightly different way than the regular use cases for Azure Virtual Desktop. Kongsberg Digital has some specific requirements for their instructor application in relation to the student application and they wanted to be in control over their instructor application. If you would like to read more about this use case, be sure to read the article about in the magazine (page 28)!\nTogether with Erwin Staal and Marc Bruins, I have written an article about Azure Landing Zones and the Cloud Adoption framework. If you want to know more about this article, be sure to read it in the magazine (page 33)!\nStay tuned for a summary of my articles in the next blog posts!\n","date":"02 Jan, 2023","image":null,"permalink":"/post/my-xpirit-magazine-articles/","tags":["Xpirit Magazine","Sharing Knowlegde"],"title":"My Xpirit Magazine Articles"}]